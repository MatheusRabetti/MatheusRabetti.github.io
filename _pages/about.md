---
layout: page
title: About Me
tags: [about]
comments: false
permalink: /about/
---

> "Generating numbers is easy, generating numbers you should trust is hard!" 

Broadly-trained data scientist with 6 years of experience, accomplished Data Scientist in complex experimentation/causality, time series forecasting, and classification models. My background is statistics with lots of side studies on economics

I have worked as a Research Assistant for a Brazilian National Research Institute, a Statistician at Labour Ministry, Product Analyst at the largest media company in Latin America (Globo), Marketing Scientist at Uber and currently working as Data Scientist at Glovo. My main areas of interest are causal inference, econometrics, and machine learning.

Proven business impact in different areas, particularly Marketing and Experimentation in the last years. Skilled at optimal decision making, causal inference, machine learning, communication, business acumen, and problem-solving. I’m driven by curiosity, challenging problems, chewing technical and academic books and seeing a problem from multiple perspectives.

Experience
============

#### @Glovo

* Building Relationship and Mapping Marketing Actions for Data Science Projects Prioritization
* Leading conversion rate prediction model for digital channels early performance comparison (Survival Analysis)
* Started Data Science Project Kick-off Meeting and Documentation (objective, action, impact, stakeholders)
* Segment Discovery of users with higher LTV increment after being impacted by Marketing campaigns that would convert only if targeted by the campaigns (Individual Treatment Effect - Uplift Modeling)
* Build reliable, precise and faster A/B tests with variance reduction (CUPED), bias correction (CUPED / Diff and Diff), identifying novelty or primacy effects, randomization unit correction (Linear Mixed Model), and Bayesian Inference.
* Moving the company culture of decision making based on correlation studies to causality analysis (instrumental variables, propensity score matching, mediation modeling, regression discontinuity, causal diagrams, and others causal inference methods)

#### @Uber 

* Methods for geo experimentation: Bayesian Hierarchical Time Series (Causal Impact), Synthetic Control, Matching Similar Cities and Regions for geo experimentation
* Market Saturation, Total Addressable Market and Opportunity Size for Engagement, Churn and Acquisition segments
* Marketing and Incentives Impact in Acquisition Metrics - short and long term impact inference.
* LAtam POC for Marketing Incrementality Tests & Measurement Methodology
* Measuring Offline and Brand Campaigns Business Impact
* Marketing Business Results Report sent monthly for key stakeholders
* Interviewing marketing data analysts

#### @Globo.com - largest media company in Latin America

* Daily business insights giving guidance for product changes (working along a software engineer and a designer)
* Implemented a churn prediction model to anticipate this decision and make actions to retain the customer.
* User Path Navigation with Markov Chain
* Building the metrics and the statistical environment on A/B platform.
* Formulating success metrics for quality of experience on player, estimating marginal effects of these metrics on engagement and using the estimates on how to prioritize what metric to act on.
* Computer Vision for predicting when the video credits start 

#### @Ministry of Labor

* Time series prediction of admissions and dismissals for the main Brazilian cities
* Monthly report of labor market monitoring metrics of affiliated municipalities
* Public Dashboard informing policy makers and the overall population in the current labor market situation

#### @IPEA - Institute of Economic and Applied Research

* An econometric analysis of the diversity on agriculture familiar production.
* Panel of social vulnerability in partnership with the UN.
* Investigates the population and employment dynamics in central urban areas of twelve selected capitals using Spatial analysis methods. Kernel heat maps were used to conceptualize and delimite central areas for each city.

Skills
============

* Favorite machine learning frameworks: Scikit-learn, Caret, XGBoost, LightGBM, Keras
* Programming Languages: R, Python, SQL
* Compute Instance: Google Compute Engine
* Data Warehouse (OLAP): Hive, Vertica, Presto, AWS Redshift, Google BigQuery
* Cloud Storage: AWS S3, Google Cloud Storage
* Distributed Machine Learning: Spark
* Job Scheduler: Airflow
* Visualisation: Tableau, Matplotlib, ggplot, Looker
* Version Control: Git
* Project Tracking: Jira, Trello

Courses
============

* [MITx: 15.071x The Analytics Edge](https://www.edx.org/course/analytics-edge-mitx-15-071x-2): MIT’s The Analytics Edge is an edX course focused on using statistical tools to gain insight about data and make predictions. It has around 75 datasets and starts from linear regression upto clustering and some classification techniques like Random Forest and CART models in between.

* [Data Science Specialization](https://www.coursera.org/specializations/jhu-data-science): This Specialization covers the concepts and tools you'll need throughout the entire data science pipeline, from asking the right kinds of questions to making inferences and publishing results.

* [Master Statistics with R](https://www.coursera.org/specializations/statistics): This Specialization showed how to analyze and visualize data in R and created reproducible data analysis reports, demonstrate a conceptual understanding of the unified nature of statistical inference, perform frequentist and Bayesian statistical inference and modeling to understand natural phenomena and make data-based decisions.

* [Digital Marketing](https://in.udacity.com/course/digital-marketing-nanodegree--nd018): This program offers you the opportunity to master platform-specific skills valued by top employers, while at the same time establishing a broad-based understanding of the whole digital marketing ecosystem. Run live campaigns on major marketing platforms, learn and apply new marketing techniques, analyze results, and produce actionable insights.

* [Causal Inference](https://www.datacamp.com/community/open-courses/causal-inference-with-r-instrumental-variables-rdd): In this series of 7 courses created by Duke University with support from eBay focuses on how to use the advanced methods of instrumental variables and regression discontinuity to find causal effects. Guides you through the concepts that data scientists need to always consider when examining and making inferences about data. 



Publications
============

1. Rabetti, M.S.; Nadalin, V.G.; Oliveira, C.A.P.; Furtado, B.A.; Cavalcanti, C.B. (2016) <a href="http://www.ipea.gov.br/portal/index.php?option=com_content&view=article&id=28469&Itemid=406"> Population and Employment Dynamics in the Urban Centers of the Brazilian Metropolis </a>. 

2. Rabetti, M.S.; Sambuichi, R.H.R.; Galindo, E.P.; Pereira, R.M.; Cconstantino, M. (2016) <a href="http://www.ipea.gov.br/portal/index.php?option=com_content&view=article&id=27858"> Production Diversity in Family Agriculture Establishments in Brazil: an econometric analysis based on the registration of the Declaration of Aptitude to Pronaf (DAP) </a>.

3. Rabetti, M.S. and Carvalho, C.H.R. (2015) <a href="http://www.ipea.gov.br/portal/images/stories/PDFs/relatoriopesquisa/150922_relatorio_acidentes_transito.pdf"> Traffic accidents on Brazilian federal highways </a>. 


Links
=====

* I worked on the development, calculation and construction along a BI team of a interactive plataform to analyse the brazilian labour market, [Painel de Monitoramento do Mercado de Trabalho](http://mercadodetrabalho.mte.gov.br/).

* I've done all analysis procedures on the IVS project, a plataform developed in partnership betweend United Nations Development Programme and Institute for Applied Economic Research, [IVS](http://ivs.ipea.gov.br/ivs/en/mapa/).

* Some results of the third publication listed above - Mapping the Economic Centers of Brazil, [RPubs Portfolio](https://rpubs.com/msrabetti/rais_leaflet)


About This Site
=========

This site is powered by [Jekyll](http://jekyllrb.com/) using the [Minimal Mistakes](http://mademistakes.com/minimal-mistakes/) theme. All blog posts are released under a [Creative Commons Attribution-ShareAlike 4.0 International License](http://creativecommons.org/licenses/by-sa/4.0/).

All R blog posts are compiled with [knitr](http://yihui.name/knitr/) [R markdown](http://rmarkdown.rstudio.com/). You can find the reproducible sources of each blog post [here](https://github.com/matheusrabetti/matheusrabetti.github.io/tree/master/_R).

